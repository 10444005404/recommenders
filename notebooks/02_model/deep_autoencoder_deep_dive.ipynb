{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Autoencoder Deep Dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: linux\n",
      "Python:  3.6.7 | packaged by conda-forge | (default, Nov 21 2018, 03:09:43) \n",
      "[GCC 7.3.0]\n",
      "PyTorch: 1.0.0\n",
      "Number of CPU processors: 6\n",
      "Number of GPUs: 1\n",
      "CUDA Version 9.2.148\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "from reco_utils.common.gpu_utils import get_number_gpus, get_cuda_version\n",
    "from reco_utils.common.general_utils import get_number_processors\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_chrono_split\n",
    "from reco_utils.evaluation.python_evaluation import rmse, mae, rsquared, exp_var\n",
    "from reco_utils.recommender.deep_autoencoder.autoencoder import AutoEncoder\n",
    "from reco_utils.recommender.deep_autoencoder.data import UserItemRecDataProvider\n",
    "from reco_utils.recommender.deep_autoencoder.utils import add_gpu, init_optimizer, MSEloss\n",
    "\n",
    "import logging\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "print(\"OS:\", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Number of CPU processors:\", get_number_processors())\n",
    "print(\"Number of GPUs:\", get_number_gpus())\n",
    "print(get_cuda_version())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"ratings_train.csv\"\n",
    "valid_path = \"ratings_valid.csv\"\n",
    "test_path = \"ratings_test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb7e70acf30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_params = {'batch_size': 128,\n",
    "                'major': 'users',  # major position is the first column id of input data\n",
    "                'itemIdInd': 1,  # the second index is the items\n",
    "                'userIdInd': 0,  # the first index is the users/customers\n",
    "                'delimiter': ',',\n",
    "                'header': True,\n",
    "                \"src_file\": train_path\n",
    "                }\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_layer = UserItemRecDataProvider(params=data_params)\n",
    "#dir(data_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_params = copy.deepcopy(data_params)\n",
    "eval_params['src_file'] = valid_path\n",
    "validation_layer = UserItemRecDataProvider(\n",
    "    params=eval_params,\n",
    "    user_id_map=data_layer.user_id_map,\n",
    "    item_id_map=data_layer.item_id_map)\n",
    "validation_layer.src_data = data_layer.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../reco_utils/recommender/deep_autoencoder/autoencoder.py:46: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  weight_init.xavier_uniform(w)\n",
      "../../reco_utils/recommender/deep_autoencoder/autoencoder.py:61: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  weight_init.xavier_uniform(w)\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = [1024, 512, 512, 128]\n",
    "model = AutoEncoder(\n",
    "    layer_sizes=[data_layer.vector_dim] + hidden_layers,\n",
    "    nl_type=\"selu\",\n",
    "    is_constrained=False,\n",
    "    dp_drop_prob=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = add_gpu(model, \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, scheduler = init_optimizer(model,\n",
    "                       optimization_method=\"momentum\",\n",
    "                       lr=0.005,\n",
    "                       wd=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "cuda_availability = True\n",
    "def train_loop(rencoder, optimizer, scheduler=None):    \n",
    "    \"\"\"\n",
    "    Internal train loop\n",
    "    \"\"\"\n",
    "    t_loss = 0.0\n",
    "    t_loss_denom = 0.0\n",
    "    global_step = 0\n",
    "    best_loss = sys.maxsize\n",
    "    best_epoch = 0\n",
    "    epoch = 0\n",
    "    losing_patience = 0\n",
    "\n",
    "    # Params\n",
    "    noise_prob = 0.0\n",
    "    num_epochs = 5\n",
    "    aug_step = 1\n",
    "\n",
    "\n",
    "    if noise_prob > 0.0:\n",
    "        dp = nn.Dropout(p=noise_prob)\n",
    "\n",
    "    # Train until finish epochs or early stoping fires\n",
    "    while epoch < num_epochs and losing_patience < 10:\n",
    "        log.debug('Doing epoch {} of {}'.format(epoch, num_epochs))\n",
    "        rencoder.train()\n",
    "        total_epoch_loss = 0.0\n",
    "        denom = 0.0\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        for i, mb in enumerate(data_layer.iterate_one_epoch()):\n",
    "            inputs = Variable(mb.cuda().to_dense()) if cuda_availability else Variable(mb.to_dense())\n",
    "            optimizer.zero_grad()\n",
    "            loss, outputs = _backprop(rencoder, inputs, optimizer)\n",
    "            global_step += 1\n",
    "            t_loss += loss.data[0]\n",
    "            t_loss_denom += 1\n",
    "            total_epoch_loss += loss.data[0]\n",
    "            denom += 1\n",
    "\n",
    "            if aug_step > 0:\n",
    "                # Magic data augmentation trick happen here\n",
    "                for t in range(aug_step):\n",
    "                    inputs = Variable(outputs.data)\n",
    "                    if noise_prob > 0.0:\n",
    "                        inputs = dp(inputs)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss, outputs = _backprop(\n",
    "                        rencoder, inputs, optimizer)\n",
    "\n",
    "        # Track model with lowest loss\n",
    "        epoch_loss = sqrt(total_epoch_loss/denom)\n",
    "        log.debug(\"Epoch {} - Training loss: {}\".format(epoch, epoch_loss))\n",
    "        if True:# self.params['use_validation']:\n",
    "            epoch_loss = _evaluate_on_validation_set(rencoder)\n",
    "            log.debug(\"Epoch {} - Validation loss: {}\".format(epoch,\n",
    "                                                              epoch_loss))\n",
    "        if epoch_loss < best_loss:\n",
    "            losing_patience = 0\n",
    "            best_loss = epoch_loss\n",
    "            best_epoch = epoch\n",
    "            best_model_wts = copy.deepcopy(rencoder.state_dict())\n",
    "        else:\n",
    "            # early stoping\n",
    "            losing_patience += 1\n",
    "        epoch += 1\n",
    "\n",
    "    # Save final model\n",
    "    log.debug(\"Best loss {} in epoch {}\".format(best_loss, best_epoch))\n",
    "    #self._save_model(best_model_wts, best_epoch)\n",
    "    #rencoder.load_state_dict(best_model_wts)\n",
    "\n",
    "def _backprop(rencoder, inputs, optimizer):\n",
    "    outputs = rencoder(inputs)\n",
    "    loss, num_ratings = autoencoder.MSEloss(outputs, inputs)\n",
    "    loss = loss / num_ratings\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, outputs\n",
    "\n",
    "def _evaluate_on_validation_set(rencoder):\n",
    "    rencoder.eval()\n",
    "    denom = 0.0\n",
    "    total_epoch_loss = 0.0\n",
    "    for target_mb, user_profile in data_layer.iterate_one_epoch_eval():\n",
    "        inputs = Variable(user_profile.cuda().to_dense()) if cuda_availability else Variable(user_profile.to_dense())\n",
    "        targets = Variable(target_mb.cuda().to_dense()) if cuda_availability else Variable(target_mb.to_dense())\n",
    "        outputs = rencoder(inputs)\n",
    "        loss, num_ratings = autoencoder.MSEloss(outputs, targets)\n",
    "        total_epoch_loss += loss.data[0]\n",
    "        denom += num_ratings.data[0]\n",
    "    return sqrt(total_epoch_loss / denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-fd7f756496d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-fd77ccb72e27>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(rencoder, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda_availability\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_backprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mt_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-fd77ccb72e27>\u001b[0m in \u001b[0;36m_backprop\u001b[0;34m(rencoder, inputs, optimizer)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_backprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSEloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "train_loop(model, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco_gpu)",
   "language": "python",
   "name": "reco_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
