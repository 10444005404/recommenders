{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RippleNet on MovieLens using Wikidata (Python, GPU)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will walk through each step of the RippleNet algorithm.\n",
    "RippleNet is an end-to-end framework that naturally incorporates the knowledge graphs into recommender systems.\n",
    "To make the results of the paper reproducible we have used MovieLens as our dataset and Wikidata as our Knowledge Graph.\n",
    "\n",
    "> RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems\n",
    "> Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, Minyi Guo\n",
    "> The 27th ACM International Conference on Information and Knowledge Management (CIKM 2018)\n",
    "\n",
    "Online code of RippleNet: https://github.com/hwwang55/RippleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the sparsity and cold start problem of collaborative filtering, researchers usually make use of side information, such as social networks or item attributes, to improve recommendation performance. This paper considers the knowledge graph as the source of side information. To address the limitations of existing embedding-based and path-based methods for knowledge-graph-aware recommendation, we propose RippleNet, an end-to-end framework that naturally incorporates the knowledge graph into recommender systems. Similar to actual ripples propagating on the water, RippleNet stimulates the propagation of user preferences over the set of knowledge entities by automatically and iteratively extending a user’s potential interests along links in the knowledge graph. The multiple \"ripples\" activated by a user’s historically clicked items are thus superposed to form the preference distribution of the user with respect to a candidate item, which could be used for predicting the final clicking probability. Through extensive experiments on real-world datasets, we demonstrate that RippleNet achieves substantial gains in a variety of scenarios, including movie, book and news recommendation, over several state-of-the-art baselines.\n",
    "\n",
    "![alt text](https://github.com/hwwang55/RippleNet/raw/master/framework.jpg)\n",
    "\n",
    "The overall framework of the RippleNet. It takes one user and one item as input, and outputs the predicted probability that the user will click the item. The KGs in the upper part illustrate the corresponding ripple sets activated by the user’s click history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "Details of the python implementation can be found [here](https://github.com/microsoft/recommenders/tree/rippleNet/reco_utils/recommender/ripplenet). The implementation is based on the original code of RippleNet: https://github.com/hwwang55/RippleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RippleNet Movie Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n",
      "Pandas version: 0.25.3\n",
      "Tensorflow version: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import papermill as pm\n",
    "\n",
    "from reco_utils.common.timer import Timer\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_stratified_split\n",
    "from reco_utils.recommender.ripplenet.preprocess import (read_item_index_to_entity_id_file, \n",
    "                                         convert_rating, \n",
    "                                         convert_kg)\n",
    "from reco_utils.recommender.ripplenet.data_loader import load_kg, get_ripple_set\n",
    "from reco_utils.recommender.ripplenet.model import RippleNet\n",
    "from reco_utils.evaluation.python_evaluation import auc, precision_at_k, recall_at_k\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Select MovieLens data size: 100k, 1M, 10M\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "rating_threshold = 4 #Minimum rating of a movie to be considered positive\n",
    "\n",
    "# Ripple parameters\n",
    "n_epoch = 10 #the number of epochs\n",
    "batch_size = 1024 #batch size\n",
    "dim = 16 #dimension of entity and relation embeddings\n",
    "n_hop = 2 #maximum hops\n",
    "kge_weight = 0.01 #weight of the KGE term\n",
    "l2_weight = 1e-7 #weight of the l2 regularization term\n",
    "lr = 0.02 #learning rate\n",
    "n_memory = 32 #size of ripple set for each hop\n",
    "item_update_mode = 'plus_transform' #how to update item at the end of each hop. \n",
    "                                    #possible options are replace, plus, plus_transform or replace transform\n",
    "using_all_hops = True #whether using outputs of all hops or just the last hop when making prediction\n",
    "optimizer_method = \"adam\" #optimizer method from adam, adadelta, adagrad, ftrl (FtrlOptimizer),\n",
    "                          #gd (GradientDescentOptimizer), rmsprop (RMSPropOptimizer)\n",
    "show_loss = False #whether or not to show the loss\n",
    "seed = 12\n",
    "\n",
    "#Evaluation parameters\n",
    "TOP_K = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read original data and transform entity ids to numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RippleNet is built on:\n",
    "- Ratings from users on Movies\n",
    "- Knowledge Graph (KG) linking Movies to their connected entities in Wikidata. See [this notebook](https://github.com/microsoft/recommenders/blob/master/notebooks/01_prepare_data/wikidata_knowledge_graph.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:00<00:00, 16.2kKB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>875747190</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>242</td>\n",
       "      <td>5.0</td>\n",
       "      <td>883888671</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  ItemId  Rating  Timestamp         Title  Genres  Year\n",
       "0     196     242     3.0  881250949  Kolya (1996)  Comedy  1996\n",
       "1      63     242     3.0  875747190  Kolya (1996)  Comedy  1996\n",
       "2     226     242     5.0  883888671  Kolya (1996)  Comedy  1996"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_original = movielens.load_pandas_df(MOVIELENS_DATA_SIZE,\n",
    "                              ('UserId', 'ItemId', 'Rating', 'Timestamp'),\n",
    "                             title_col='Title',\n",
    "                             genres_col='Genres',\n",
    "                             year_col='Year')\n",
    "ratings_original.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_entity</th>\n",
       "      <th>linked_entities</th>\n",
       "      <th>name_linked_entities</th>\n",
       "      <th>movielens_title</th>\n",
       "      <th>movielens_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1141186</td>\n",
       "      <td>Q130232</td>\n",
       "      <td>drama film</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1141186</td>\n",
       "      <td>Q157443</td>\n",
       "      <td>comedy film</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1141186</td>\n",
       "      <td>Q10819887</td>\n",
       "      <td>Andrei Chalimon</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_entity linked_entities name_linked_entities movielens_title  \\\n",
       "0        Q1141186         Q130232           drama film    Kolya (1996)   \n",
       "1        Q1141186         Q157443          comedy film    Kolya (1996)   \n",
       "2        Q1141186       Q10819887      Andrei Chalimon    Kolya (1996)   \n",
       "\n",
       "   movielens_id  \n",
       "0           242  \n",
       "1           242  \n",
       "2           242  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_original = pd.read_csv(\"https://recodatasets.blob.core.windows.net/wikidata/movielens_{}_wikidata.csv\".format(MOVIELENS_DATA_SIZE))\n",
    "kg_original.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to link the Ratings and KG ids we create two dictionaries match the KG original IDs to homogeneous numerical IDs. This will be done in two steps:\n",
    "1. Transforming both Rating ID and KG ID to numerical\n",
    "2. Matching the IDs using a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_id(df, entities_id, col_transform, col_name = \"unified_id\"):\n",
    "    df = df.merge(entities_id, left_on = col_transform, right_on = \"entity\")\n",
    "    df = df.rename(columns = {\"unified_id\": col_name})\n",
    "    return df.drop(columns = [col_transform, \"entity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unified_id</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Q509628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Q4984790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Q2463968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unified_id    entity\n",
       "0           0   Q509628\n",
       "1           1  Q4984790\n",
       "2           2  Q2463968"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dictionary that matches KG Wikidata ID to internal numerical KG ID\n",
    "entities_id = pd.DataFrame({\"entity\":list(set(kg_original.original_entity)) + list(set(kg_original.linked_entities))}).reset_index()\n",
    "entities_id = entities_id.rename(columns = {\"index\": \"unified_id\"})\n",
    "entities_id.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_entity_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>linked_entities_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "      <td>6449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10417</td>\n",
       "      <td>1</td>\n",
       "      <td>6449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1378</td>\n",
       "      <td>1</td>\n",
       "      <td>6449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_entity_id  relation  linked_entities_id\n",
       "0                1072         1                6449\n",
       "1               10417         1                6449\n",
       "2                1378         1                6449"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tranforming KG IDs to internal numerical KG IDs created above \n",
    "kg = kg_original[[\"original_entity\", \"linked_entities\"]].drop_duplicates()\n",
    "kg = transform_id(kg, entities_id, \"original_entity\", \"original_entity_id\")\n",
    "kg = transform_id(kg, entities_id, \"linked_entities\", \"linked_entities_id\")\n",
    "kg[\"relation\"] = 1\n",
    "kg_wikidata = kg[[\"original_entity_id\",\"relation\", \"linked_entities_id\"]]\n",
    "kg_wikidata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movielens_id</th>\n",
       "      <th>unified_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>242</td>\n",
       "      <td>10417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>1378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movielens_id  unified_id\n",
       "0           242        1072\n",
       "1           242       10417\n",
       "2           302        1378"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dictionary matching Movielens ID to internal numerical KG ID created above\n",
    "var_id = \"movielens_id\"\n",
    "item_to_entity = kg_original[[var_id, \"original_entity\"]].drop_duplicates().reset_index().drop(columns = \"index\")\n",
    "item_to_entity = transform_id(item_to_entity, entities_id, \"original_entity\")\n",
    "item_to_entity.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_movielens = [\"UserId\", \"ItemId\", \"Rating\", \"Timestamp\"]\n",
    "ratings = ratings_original[vars_movielens].sort_values(vars_movielens[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess module from RippleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The dictionaries created above will be used on the Ratings and KG dataframes and unify their IDs. Also the Ratings will be converted from a numerical rating (1-5) to a binary rating (0-1) using the rating_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dictionary Movielens ID - numerical KG ID to extract two dictionaries to be used on Ratings and KG\n",
    "item_index_old2new, entity_id2index = read_item_index_to_entity_id_file(item_to_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reco_utils.recommender.ripplenet.preprocess:converting rating file ...\n",
      "INFO:reco_utils.recommender.ripplenet.preprocess:number of users: 942\n",
      "INFO:reco_utils.recommender.ripplenet.preprocess:number of items: 1677\n"
     ]
    }
   ],
   "source": [
    "ratings_final = convert_rating(ratings, item_index_old2new = item_index_old2new,\n",
    "                               threshold = rating_threshold, seed = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reco_utils.recommender.ripplenet.preprocess:converting kg file ...\n",
      "INFO:reco_utils.recommender.ripplenet.preprocess:number of entities (containing items): 22994\n",
      "INFO:reco_utils.recommender.ripplenet.preprocess:number of relations: 1\n"
     ]
    }
   ],
   "source": [
    "kg_final = convert_kg(kg_wikidata, entity_id2index = entity_id2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data and Build RippleSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is divided into train, test and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, eval_data = python_stratified_split(ratings_final, ratio=[0.6, 0.2, 0.2], col_user='user_index', col_item='item', seed=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_index</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>original_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>3281</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0</td>\n",
       "      <td>3273</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_index  item  rating  original_rating\n",
       "129           0  3281       0              0.0\n",
       "231           0  1407       0              0.0\n",
       "52            0   461       1              4.0\n",
       "229           0  3273       0              0.0\n",
       "250           0  2007       0              0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original KG dataframe is transformed into a dictionary, and the number of entities and retaltions extracted as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reco_utils.recommender.ripplenet.data_loader:reading KG file ...\n"
     ]
    }
   ],
   "source": [
    "n_entity, n_relation, kg = load_kg(kg_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rippleset dictionary is built on the positive ratings (relevant entities) of the training data, and using the KG to build set of knowledge triples per user positive rating, from 0 until n_hop.\n",
    "\n",
    "**Relevant entity**: Given interaction matrix Y and knowledge graph G, the set of k-hop relevant entities for user u is defined as\n",
    "\n",
    "$$E^{k}_{u} = \\{t\\ |\\ (h,r,t) ∈ G\\ and\\ h ∈ E^{k−1}_{u}\\}, k=1,2,...,H$$\n",
    "\n",
    "Where $E_{u} = V_{u} = \\{v|yuv =1\\}$ is the set of user’s clicked items in the past, which can be seen as the seed set of user $u$ in KG\n",
    "\n",
    "**RippleSet**: The k-hop rippleset of user $u$ is defined as the set of knowledge triples starting from $E_{k−1}$:\n",
    "\n",
    "$$S^{k}_{u} = \\{(h,r,t)\\ |\\ (h,r,t) ∈ G\\ and\\ h ∈ E^{k−1}_{u}\\}, k = 1,2,...,H$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reco_utils.recommender.ripplenet.data_loader:constructing ripple set ...\n"
     ]
    }
   ],
   "source": [
    "user_history_dict = train_data.loc[train_data.rating == 1].groupby('user_index')['item'].apply(list).to_dict()\n",
    "ripple_set = get_ripple_set(kg, user_history_dict, n_hop=n_hop, n_memory=n_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple = RippleNet(dim=dim,n_hop=n_hop,\n",
    "                   kge_weight=kge_weight, l2_weight=l2_weight, lr=lr,\n",
    "                   n_memory=n_memory,\n",
    "                   item_update_mode=item_update_mode, using_all_hops=using_all_hops,\n",
    "                   n_entity=n_entity,n_relation=n_relation,\n",
    "                   optimizer_method=optimizer_method,\n",
    "                   seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[6,12] = 22991 is not in [0, 22908)\n\t [[node embedding_lookup_6 (defined at ../../reco_utils/recommender/ripplenet/model.py:159)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_DOUBLE, _class=[\"loc:@Adam/Assign_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](entity_emb_matrix/read, _arg_memories_t_1_0_7, embedding_lookup/axis)]]\n\nCaused by op 'embedding_lookup_6', defined at:\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n    yield self.process_one()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 714, in __init__\n    self.run()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-b8b001ee6b13>\", line 7, in <module>\n    seed=seed)\n  File \"../../reco_utils/recommender/ripplenet/model.py\", line 74, in __init__\n    self._build_model()\n  File \"../../reco_utils/recommender/ripplenet/model.py\", line 159, in _build_model\n    tf.nn.embedding_lookup(self.entity_emb_matrix, self.memories_t[i])\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 313, in embedding_lookup\n    transform_fn=None)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2675, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3332, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[6,12] = 22991 is not in [0, 22908)\n\t [[node embedding_lookup_6 (defined at ../../reco_utils/recommender/ripplenet/model.py:159)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_DOUBLE, _class=[\"loc:@Adam/Assign_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](entity_emb_matrix/read, _arg_memories_t_1_0_7, embedding_lookup/axis)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[6,12] = 22991 is not in [0, 22908)\n\t [[{{node embedding_lookup_6}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_DOUBLE, _class=[\"loc:@Adam/Assign_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](entity_emb_matrix/read, _arg_memories_t_1_0_7, embedding_lookup/axis)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0bb7a5bc8c82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user_index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"item\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0mripple_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mripple_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                show_loss=show_loss)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Took {} seconds for training.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/home/hoaphumanoid/notebooks/repos/recommenders/reco_utils/recommender/ripplenet/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, batch_size, train_data, ripple_set, show_loss)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 _, loss = self._train(\n\u001b[1;32m    334\u001b[0m                     self._get_feed_dict(\n\u001b[0;32m--> 335\u001b[0;31m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m                     )\n\u001b[1;32m    337\u001b[0m                 )\n",
      "\u001b[0;32m/data/home/hoaphumanoid/notebooks/repos/recommenders/reco_utils/recommender/ripplenet/model.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, feed_dict)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_return_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[6,12] = 22991 is not in [0, 22908)\n\t [[node embedding_lookup_6 (defined at ../../reco_utils/recommender/ripplenet/model.py:159)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_DOUBLE, _class=[\"loc:@Adam/Assign_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](entity_emb_matrix/read, _arg_memories_t_1_0_7, embedding_lookup/axis)]]\n\nCaused by op 'embedding_lookup_6', defined at:\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n    yield self.process_one()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 714, in __init__\n    self.run()\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-b8b001ee6b13>\", line 7, in <module>\n    seed=seed)\n  File \"../../reco_utils/recommender/ripplenet/model.py\", line 74, in __init__\n    self._build_model()\n  File \"../../reco_utils/recommender/ripplenet/model.py\", line 159, in _build_model\n    tf.nn.embedding_lookup(self.entity_emb_matrix, self.memories_t[i])\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 313, in embedding_lookup\n    transform_fn=None)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2675, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3332, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/data/anaconda/envs/reco_base/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[6,12] = 22991 is not in [0, 22908)\n\t [[node embedding_lookup_6 (defined at ../../reco_utils/recommender/ripplenet/model.py:159)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_DOUBLE, _class=[\"loc:@Adam/Assign_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](entity_emb_matrix/read, _arg_memories_t_1_0_7, embedding_lookup/axis)]]\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    ripple.fit(n_epoch=n_epoch, batch_size=batch_size,\n",
    "               train_data=train_data[[\"user_index\", \"item\", \"rating\"]].to_numpy(), \n",
    "               ripple_set=ripple_set,\n",
    "               show_loss=show_loss)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as test_time:\n",
    "    labels, scores = ripple.predict(batch_size=batch_size, \n",
    "                                    data=test_data[[\"user_index\", \"item\", \"rating\"]].to_numpy())\n",
    "    predictions = [1 if i >= 0.5 else 0 for i in scores]\n",
    "    \n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you need to re-create the RippleNet again, simply run:\n",
    "```python\n",
    "tf.reset_default_graph()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['scores'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = auc(test_data, test_data, \n",
    "            col_user=\"user_index\",\n",
    "            col_item=\"item\",\n",
    "            col_rating=\"rating\",\n",
    "            col_prediction=\"scores\")\n",
    "print(\"The auc score is {}\".format(auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = np.mean(np.equal(predictions, labels))\n",
    "print(\"The acc score is {}\".format(acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_k_score = precision_at_k(test_data, test_data, \n",
    "            col_user=\"user_index\",\n",
    "            col_item=\"item\",\n",
    "            col_rating=\"original_rating\",\n",
    "            col_prediction=\"scores\",\n",
    "            relevancy_method=\"top_k\",\n",
    "            k=TOP_K)\n",
    "print(\"The precision_k_score score at k = {}, is {}\".format(TOP_K, precision_k_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_k_score = recall_at_k(test_data, test_data, \n",
    "            col_user=\"user_index\",\n",
    "            col_item=\"item\",\n",
    "            col_rating=\"original_rating\",\n",
    "            col_prediction=\"scores\",\n",
    "            relevancy_method=\"top_k\",\n",
    "            k=TOP_K)\n",
    "print(\"The recall_k_score score at k = {}, is {}\".format(TOP_K, recall_k_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record results with papermill for tests - ignore this cell\n",
    "pm.record(\"auc\", auc_score)\n",
    "pm.record(\"precision\", precision_k_score)\n",
    "pm.record(\"recall\", recall_k_score)\n",
    "pm.record(\"train_time\", train_time.interval)\n",
    "pm.record(\"test_time\", test_time.interval)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python (reco_base)",
   "language": "python",
   "name": "reco_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
